# Perceptron
Perceptrón multicapa que hice para practicar. Uso un descenso de gradiente estocástico, tiene más de 2 capas aunque falta corregir la derivada para más de 3 dimensiones. Me basé en lo visto en mi curso de Teoría de la Computación e Inteligencia Artificial.
Ya hice las cuentas, solo falta implementarlo, pero lo dejaré para después. Si sirve, hago esas cuentas otra vez.

### Dependencias 
```
Numpy
matplotlib
random
math

```
